# v5: コンテキスト圧縮

**コアの洞察: 忘れることは欠陥ではなく、能力である。**

v0-v4には暗黙の前提がある：対話履歴は無限に伸ばせる。現実はそうではない。

## 問題

```
200K tokenのコンテキストウィンドウ:
  [システムプロンプト]     ~2K tokens
  [CLAUDE.md]             ~3K tokens
  [ツール定義]             ~8K tokens
  [対話履歴]               増え続ける...
  [第50回ツール呼び出し]   -> 約180K tokens
  [第60回ツール呼び出し]   -> 200K超過、リクエスト失敗
```

複雑なリファクタリングは100回以上のツール呼び出しが必要になる場合がある。圧縮なしでは、エージェントは壁にぶつかる。

## 三層圧縮

一種類の圧縮ではなく、三段階の構造:

| レイヤー | トリガー | 動作 | ユーザー体験 |
|----------|----------|------|-------------|
| マイクロ圧縮 | 毎ターン自動 | 古いツール出力をクリア | 無感知 |
| 自動圧縮 | 上限付近（約93%） | 対話全体を要約に圧縮 | 通知表示 |
| 手動圧縮 | `/compact` コマンド | ユーザー指示に沿った圧縮 | 主体的に実行 |

## マイクロ圧縮: サイレントクリーニング

毎ターン、古い大型ツール出力をプレースホルダーに置換。最近のものは保持:

```python
COMPACTABLE_TOOLS = {"Bash", "Read", "Grep", "Glob"}
KEEP_RECENT = 3

def microcompact(messages):
    """古い大型ツール結果をプレースホルダーに置換"""
    tool_results = find_tool_results(messages, COMPACTABLE_TOOLS)

    for result in tool_results[:-KEEP_RECENT]:
        if estimate_tokens(result) > 1000:
            result["content"] = "[Output compacted - re-read if needed]"

    return messages
```

重要な点: **内容**のみクリアし、ツール呼び出しの構造は保持する。モデルは何を呼び出したか知っている。古い出力が見えないだけで、必要なら再度読めばいい。

## 自動圧縮: 全体要約

コンテキストがウィンドウ上限（約93%）に近づくとトリガー:

```python
def auto_compact(messages):
    # 1. 完全な記録をディスクに保存（データは失われない）
    save_transcript(messages)

    # 2. モデルで要約を生成
    summary = call_api("Summarize this conversation chronologically: "
                       "goals, actions, decisions, current state...")

    # 3. 古いメッセージを要約で置換、最近の数ターンは保持
    return [
        {"role": "user", "content": f"[Conversation compressed]\n{summary}"},
        *messages[-5:]  # 最近の対話を保持
    ]
```

**重要な設計**: 要約は対話履歴（userメッセージ）に注入。システムプロンプトは変更しない。これによりシステムプロンプトのprompt cacheが常に有効。

## 大型出力の降格

単一のツール出力が大きすぎる場合、ディスクに保存してプレビューを返す:

```python
def handle_tool_output(output):
    if estimate_tokens(output) > 40000:
        path = save_to_disk(output)
        return f"Output too large. Saved to: {path}\nPreview:\n{output[:2000]}..."
    return output
```

## 圧縮タイミング

```
毎ターンの流れ:
  1. ユーザー入力
  2. マイクロ圧縮: 古いツール出力をクリア（サイレント）
  3. コンテキストサイズを確認:
     - 正常: 続行
     - 上限付近: 自動圧縮 -> 要約生成 -> 作業継続
     - 上限到達: 新規リクエストをブロック
  4. モデル応答 + ツール実行
  5. ツール出力サイズを確認（大きすぎれば降格）
  6. ステップ1に戻る
```

## サブエージェントも圧縮する

v3のサブエージェントは独立したコンテキストウィンドウを持ち、同様に圧縮を実行:

```python
def run_subagent(prompt, agent_type):
    sub_messages = [{"role": "user", "content": prompt}]

    while True:
        if should_compact(sub_messages):
            sub_messages = auto_compact(sub_messages)

        response = call_api(sub_messages)
        if response.stop_reason != "tool_use":
            break
        # ...

    return extract_final_text(response)
```

ディスク永続化の設計は後続の仕組みの基盤となる: 後の章で導入されるタスクシステムやマルチエージェント機構のデータはディスク上にあり、圧縮の影響を受けない。

## 比較

| 側面 | v4以前（圧縮なし） | v5（三層圧縮） |
|------|-------------------|----------------|
| 最大対話長 | コンテキストウィンドウに制限 | 理論上無限 |
| 長いタスクの信頼性 | コンテキスト溢れでクラッシュ | 優雅に降格 |
| 履歴データ | すべてメモリ内 | ディスク永続化 + メモリ要約 |
| 復旧能力 | なし | 要約または記録から復旧 |

## より深い洞察

> **人間の作業記憶にも限界がある。**

私たちは書いたすべてのコードを覚えているわけではない。「何をしたか、なぜしたか、現在の状態」を覚えている。圧縮はこの認知パターンを模倣する:

- マイクロ圧縮 = 短期記憶の自動減衰
- 全体圧縮 = 詳細記憶から概念記憶への転換
- ディスク記録 = 遡れる長期記憶

完全な記録は常にディスク上にある。圧縮が影響するのは作業記憶だけであり、アーカイブではない。

---

**コンテキストは有限、作業は無限。圧縮でエージェントは止まらない。**

[<< v4](./v4-スキル機構.md) | [READMEに戻る](../README_ja.md) | [v6 >>](./v6-タスクシステム.md)
