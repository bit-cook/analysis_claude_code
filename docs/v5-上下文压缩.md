# v5: 上下文压缩

**核心洞察：遗忘是一种能力，不是缺陷。**

v0-v4 有一个隐含假设：对话历史可以无限增长。现实中不是这样。

## 问题

```
200K token 的上下文窗口：
  [系统提示词]     ~2K tokens
  [CLAUDE.md]      ~3K tokens
  [工具定义]        ~8K tokens
  [对话历史]        持续增长...
  [第 50 次工具调用] -> 接近 180K tokens
  [第 60 次工具调用] -> 超过 200K, 请求失败
```

一个复杂的重构任务可能需要 100+ 次工具调用。不压缩，Agent 就会撞墙。

## 三层压缩

不是一种压缩，而是三层递进：

| 层级 | 触发 | 做什么 | 用户感知 |
|------|------|--------|---------|
| 微压缩 | 每轮自动 | 清理旧工具输出 | 无感知 |
| 自动压缩 | 接近上限时 | 整个对话压缩为摘要 | 看到提示 |
| 手动压缩 | `/compact` 命令 | 按用户指令定制压缩 | 主动触发 |

## 微压缩：静默清理

每轮对话后，替换旧的大型工具输出为占位符，保留最近几个：

```python
COMPACTABLE_TOOLS = {"Bash", "Read", "Grep", "Glob"}
KEEP_RECENT = 3

def microcompact(messages):
    """替换旧的大型工具结果为占位符"""
    tool_results = find_tool_results(messages, COMPACTABLE_TOOLS)

    for result in tool_results[:-KEEP_RECENT]:
        if estimate_tokens(result) > 1000:
            result["content"] = "[Output compacted - re-read if needed]"

    return messages
```

关键：只清理**内容**，保留工具调用的结构。模型仍然知道它调用过什么，只是看不到旧输出了。需要时重新读取即可。

## 自动压缩：整体摘要

当上下文接近窗口上限（约 93%）时触发：

```python
def auto_compact(messages):
    # 1. 保存完整转录到磁盘（永不丢失）
    save_transcript(messages)

    # 2. 用模型生成摘要
    summary = call_api("Summarize this conversation chronologically: "
                       "goals, actions, decisions, current state...")

    # 3. 用摘要替换旧消息，保留最近几轮
    return [
        {"role": "user", "content": f"[Conversation compressed]\n{summary}"},
        *messages[-5:]  # 保留最近的对话
    ]
```

**关键设计**：摘要注入到对话历史（user message），不修改系统提示词。这样系统提示词的 prompt cache 始终有效。

## 大型输出降级

单次工具输出过大时，存盘返回预览：

```python
def handle_tool_output(output):
    if estimate_tokens(output) > 40000:
        path = save_to_disk(output)
        return f"Output too large. Saved to: {path}\nPreview:\n{output[:2000]}..."
    return output
```

## 压缩时序

```
每轮对话:
  1. 用户输入
  2. 微压缩: 清理旧工具输出（静默）
  3. 检查上下文大小:
     - 正常: 继续
     - 接近上限: 触发自动压缩 -> 生成摘要 -> 继续工作
     - 到达上限: 阻止新请求
  4. 模型响应 + 工具执行
  5. 检查工具输出大小（过大则降级）
  6. 回到步骤 1
```

## 子代理也压缩

v3 的子代理有独立的上下文窗口，同样执行压缩：

```python
def run_subagent(prompt, agent_type):
    sub_messages = [{"role": "user", "content": prompt}]

    while True:
        if should_compact(sub_messages):
            sub_messages = auto_compact(sub_messages)

        response = call_api(sub_messages)
        if response.stop_reason != "tool_use":
            break
        # ...

    return extract_final_text(response)
```

压缩的磁盘持久化设计为后续机制奠定基础：后续章节引入的任务系统和多代理机制，数据都存在磁盘上，不受压缩影响。

## 对比

| 方面 | v4 以前（无压缩） | v5（三层压缩） |
|------|-------------|---------------|
| 最大对话长度 | 受限于上下文窗口 | 理论上无限 |
| 长任务可靠性 | 上下文溢出后崩溃 | 优雅降级 |
| 历史数据 | 全在内存 | 磁盘持久化 + 内存摘要 |
| 恢复能力 | 无 | 从摘要或转录恢复 |

## 更深的洞察

> **人类的工作记忆也是有限的。**

我们不会记住写过的每一行代码，而是记住"做了什么、为什么做、当前状态"。压缩模拟了这种认知模式：

- 微压缩 = 短期记忆自动衰减
- 全量压缩 = 从细节记忆转为概念记忆
- 磁盘转录 = 可回溯的长期记忆

完整记录永远在磁盘上。压缩只影响工作记忆，不影响存档。

---

**上下文有限，工作无限。压缩让 Agent 永不停歇。**

[<< v4](./v4-Skills机制.md) | [返回 README](../README_zh.md) | [v6 >>](./v6-Tasks系统.md)
